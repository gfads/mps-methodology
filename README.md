# MPS-Methodology

MPS methodology is a project that proposes applying the Multiple Preditors System (MPS) to forecasts time series
extracted from Microservice-Based Applications (MBAs). In literature, works have applied time series forecasting to
predict performance degradation in MBAs. However, all these studies use a single forecast model, which increases the
risk of inaccurate estimates, which can lead the application to undesirable scenarios such as unavailability. MPS
emerges as an alternative to this problem since it uses multiple models in the forecast. MPS's basic idea of the
ensemble
is to combine the strengths of different learning algorithms to build a more accurate and reliable forecasting system.

More reliable and accurate forecasting systems are essential in proactive microservice auto-scaling systems. They
improve the decision-making process of these systems by more reliably estimating microservices trends while mitigating
incorrect adaptations triggered by inaccurate estimates. Consequently, microservices have a reduction in operating
costs, and their customer satisfaction is maintained.

# Installation

## How to install the software?

    $ virtualenv venv
    $ source venv/bin/activate
    $ pip3 install -r requirements.txt

# What do the folders generated by the results mean?

All processor results were stored in the Results folder.

The description of each folder and its respective content is given below:

| Folder                                                                                         | Content description                                                                                   |
|------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|
| [Increasing](Results/increasing)                                                               | It contains the accuracy of monolithic models in Increasing workload.                                 |
| [Decreasing](Results/decreasing)                                                               | It contains the accuracy of monolithic models in Decreasing workload.                                 |
| [Periodic](Results/periodic)                                                                   | It contains the accuracy of monolithic models in Periodic workload.                                   |
| [Random](Results/random)                                                                       | It contains the accuracy of monolithic models in Random workload.                                     |
| [Series 1](Results/microservice1)                                                              | It contains the accuracy of monolithic models in Series 1 workload.                                   |
| [Series 2](Results/microservice2)                                                              | It contains the accuracy of monolithic models in Series 2 workload.                                   |
| [Series 3](Results/microservice3)                                                              | It contains the accuracy of monolithic models in Series 3 workload.                                   |
| [Series 4](Results/microservice4)                                                              | It contains the accuracy of monolithic models in Series 4 workload.                                   |
| [Summary](Results/summary)                                                                     | It contains the summary with precision of all approaches (monolithic, homogeneous and heterogeneous). |
| [Summary/better_lags](Results/summary/better_lags)                                             | It contains the best lag for each monolithic model.                                                   |
| [Summary/better_acurracy](Results/summary/better_acurracy)                                     | It contains the best accuracy values for each monolithic model.                                       |
| [Summary/better_pool_values](Results/summary/better_pool_values)                               | MPS accuracy.                                                                                         |
| [Summary/better_pool_values_aggregate](Results/summary/better_pool_values_aggregate)           | It contains aggregated data of better_pool_values and better_acurracy                                 |
| [Summary/pool_size_homogeneous_analisys](Results/other-results/pool_size_homogeneous_analisys) | It contains data from each time series's optimal bagging size analysis.                               |
| [Multiple Metrics](Results/other-results/multiple-metrics)                                     | It contains a summary of results on additional metrics beyond RMSE                                    |
| [DM test](Results/other-results/DM)                                                            | it contains data from the DM statistical test.                                                        |


# How to regenerate paper results using saved models?

## Download and extract from the models

Download the models
from [OneDrive](https://cinufpe-my.sharepoint.com/:u:/g/personal/wrms_cin_ufpe_br/EeIxei1a_cROlds52BQXxg4BTPKXMBocZIWMGwJFp1zvZg?e=nEiMbi) and save them inside the MPS Methodology folder. Models were uploaded externally due to their size.

    $ unzip models.zip

## Regenerate all results

Be patient. This process can take a while. Between 15-30 minutes per performance metric.

    $ rm Results/ -r; mkdir Results/
    $ python3 generate_initial_results.py --competence_measure rmse --deployment frontend --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metrics cpu memory responsetime traffic  --workloads decreasing increasing random periodic
    $ python3 generate_pool_results.py --competence_measure rmse --deployment frontend --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metric cpu memory traffic responsetime --workloads decreasing increasing random periodic
    
For real-world time series, you have to execute the command per series:
    
    $ python3 generate_initial_results.py --competence_measure rmse --deployment microservice1 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metrics cpu memory responsetime traffic  --workloads microservice1;
    $ python3 generate_pool_results.py --competence_measure rmse --deployment microservice1 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metric cpu memory traffic responsetime --workloads microservice1;
    
    and 

    $ python3 generate_initial_results.py --competence_measure rmse --deployment microservice2 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metrics cpu memory responsetime traffic  --workloads microservice2;
    $ python3 generate_pool_results.py --competence_measure rmse --deployment microservice2 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metric cpu memory traffic responsetime --workloads microservice2;
    
    and so on.
    


If desired, you can generate the values of a specific metric by changing the input command. For example, to generate
results for just the memory metric, do:

    $ python3 generate_initial_results.py --competence_measure rmse --deployment frontend --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metrics memory  --workloads decreasing increasing random periodic;
    $ python3 generate_pool_results.py --competence_measure rmse --deployment frontend --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metric memory --workloads decreasing increasing random periodic;
    
    or
    
    $ python3 generate_initial_results.py --competence_measure rmse --deployment microservice1 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metrics memory  --workloads microservice1;
    $ python3 generate_pool_results.py --competence_measure rmse --deployment microservice1 --lags 10 20 30 40 50 60 --learning_algorithms arima lstm xgboost svr rf mlp --metric memory --workloads microservice1;
        

<<<<<<< HEAD
# Summary of other information presented throughout the paper.

## Learning algorithm parameters

|                 Algorithm                  |                                                                                                                 Hyper-parameters                                                                                                                 |                                   Source                                    |
|:------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:---------------------------------------------------------------------------:|
|  [ARIMA](training_of_models.py?plain=355)  |                                                                      [Autoarima library](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)                                                                      |                                      -                                      |
|  [LSTM](training_of_models.py?plain=274)   |                                                           `batch_size`: [64, 128],  `epochs`: [1, 2, 4, 8, 10], `hidden_layers`: [2, 3, 4, 5, 6], `learning_rate`: [0.05, 0.01, 0.001]                                                           |        [Coulson et. al.](https://doi.org/10.1109/JIOT.2020.2964405)         |
|   [MLP](training_of_models.py?plain=78)    |                           `hidden layer sizes`: [5, 10, 15, 20], `activation`: [ tanh, relu, logistic], `solver`: [lbfgs, sgd, adam], ‘max iter’: [100, 500, 1000, 2000, 3000], ‘learning rate’: [ constant, adaptive]                           | [Rubak](https://www.diva-portal.org/smash/get/diva2:1776407/FULLTEXT02.pdf) |
|   [RF](training_of_models.py?plain=178)    |                                                                      `min_samples_leaf`: [1, 5, 10], `min_samples_split`: [2, 5, 10, 15], `n_estimators`: [100, 500, 1,000]                                                                      |        [Espinosa et al.](https://doi.org/10.1016/j.asoc.2021.107850)        |
|   [SVR](training_of_models.py?plain=45)    |                                                        `gamma`: [0.001,  0.01,  0.1, 1], `kernel`: [rbf, sigmoid], `epsilon`: [0.1, 0.001, 0.0001] `C`: [0.1, 1, 10, 100, 1,000, 10,000]                                                         |      [de Oliveira et al.](https://doi.org/10.1109/tnnls.2021.3051384)       |
| [XGBoost](training_of_models.py?plain=223) | `col_sample_by_tree`: [0.4, 0.6, 0.8], `gamma`: [1, 5, 10], `learning_rate`: [0.01, 0.1, 1], `max_depth`: [3, 6, 10], `n_estimators`: [100, 150, 200], `reg_alpha`: [0.01, 0.1, 10], `reg_lambda`: [0.01, 0.1, 10], `subsample`: [0.4, 0.6, 0.8] |          [Mohamed and El-Gayar](http://hdl.handle.net/10125/70820)          |

## Lags and Bagging Size

The results for selecting the homogeneous pool size are
summarised [here](Results/other-results/pool_size_homogeneous_analisys). Also, the results of the best monolithic model by
dataset and its lag size are available [here](Results/summary/better_acurracy) and [here](Results/summary/better_lags),
respectively.

The following table summarises both results for synthetic series.

<table><thead><tr><th>Datasets</th><th></th><th>Approaches</th><th></th><th></th></tr></thead><tbody><tr><td>Time Series</td><td>Workload</td><td>Best Monolithic</td><td>Monolithic Lag</td><td>Homogeneous Pool Size</td></tr><tr><td rowspan="4">CPU<br>Usage</td><td>Decreasing</td><td>SVR</td><td>30</td><td>20</td></tr><tr><td>Increasing</td><td>MLP</td><td>30</td><td>40</td></tr><tr><td>Periodic</td><td>SVR</td><td>10</td><td>50</td></tr><tr><td>Random</td><td>MLP</td><td>10</td><td>90</td></tr><tr><td rowspan="4">Memory<br><br></td><td>Decreasing</td><td>SVR</td><td>50</td><td>20</td></tr><tr><td>Increasing</td><td>SVR</td><td>20</td><td>10</td></tr><tr><td>Periodic</td><td>MLP</td><td>10</td><td>20</td></tr><tr><td>Random</td><td>SVR</td><td>10</td><td>10</td></tr><tr><td rowspan="4">Response<br>Time</td><td>Decreasing</td><td>LSTM</td><td>20</td><td>30</td></tr><tr><td>Increasing</td><td>MLP</td><td>60</td><td>30</td></tr><tr><td>Periodic</td><td>MLP</td><td>60</td><td>110</td></tr><tr><td>Random</td><td>MLP</td><td>20</td><td>140</td></tr><tr><td rowspan="4">Traffic<br><br></td><td>Decreasing</td><td>MLP</td><td>50</td><td>110</td></tr><tr><td>Increasing</td><td>MLP</td><td>20</td><td>130</td></tr><tr><td>Periodic</td><td>SVR</td><td>60</td><td>50</td></tr><tr><td>Random</td><td>MLP</td><td>10</td><td>10</td></tr></tbody></table>

The following table summarises both results for real-world series.

<table><thead><tr><th>Datasets</th><th></th><th>Approaches</th><th></th><th></th></tr></thead><tbody><tr><td>Time Series</td><td>Workload</td><td>Best Monolithic</td><td>Monolithic Lag</td><td>Homogeneous Pool Size</td></tr><tr><td rowspan="4">CPU<br>Usage</td><td>Decreasing</td><td>SVR</td><td>10</td><td>20</td></tr><tr><td>Increasing</td><td>SVR</td><td>40</td><td>20</td></tr><tr><td>Periodic</td><td>SVR</td><td>20</td><td>20</td></tr><tr><td>Random</td><td>MLP</td><td>10</td><td>10</td></tr><tr><td rowspan="4">Memory<br><br></td><td>Decreasing</td><td>SVR</td><td>40</td><td>150</td></tr><tr><td>Increasing</td><td>SVR</td><td>10</td><td>110</td></tr><tr><td>Periodic</td><td>MLP</td><td>60</td><td>10</td></tr><tr><td>Random</td><td>SVR</td><td>10</td><td>130</td></tr><tr><td rowspan="4">Response<br>Time</td><td>Decreasing</td><td>SVR</td><td>10</td><td>20</td></tr><tr><td>Increasing</td><td>MLP</td><td>50</td><td>30</td></tr><tr><td>Periodic</td><td>XGBoost</td><td>20</td><td>30</td></tr><tr><td>Random</td><td>RF</td><td>40</td><td>100</td></tr><tr><td rowspan="4">Traffic<br><br></td><td>Decreasing</td><td>RF</td><td>20</td><td>30</td></tr><tr><td>Increasing</td><td>MLP</td><td>10</td><td>60</td></tr><tr><td>Periodic</td><td>SVR</td><td>50</td><td>90</td></tr><tr><td>Random</td><td>LSTM</td><td>20</td><td>30</td></tr></tbody></table>

## Time Series

The time series used in the research can be found [here](Time%20Series). Also, we also [plot](Time%20Series/plots)
all-time series and create a [description file](Time%20Series/series-description/).

The following table describes the synthetic series.

<table><thead><tr><th>Metric</th><th>Series</th><th>Trend</th><th>Stationary</th><th>Frequency</th><th>Mean</th><th>Median</th><th>Std</th><th>Size</th></tr></thead><tbody><tr><td rowspan="4">CPU<br>Usage</td><td>Decreasing</td><td>✓</td><td>✕</td><td>Minutes</td><td>244.278</td><td>260.606</td><td>44.418</td><td>4320</td></tr><tr><td>increasing</td><td>✓</td><td>✓</td><td>Minutes</td><td>148.470</td><td>160.590</td><td>33.122</td><td>4321</td></tr><tr><td>Periodic</td><td>✕</td><td>✓</td><td>Minutes</td><td>221.668</td><td>272.340</td><td>89.298</td><td>4322</td></tr><tr><td>Random</td><td>✕</td><td>✕</td><td>Minutes</td><td>233.277</td><td>237.980</td><td>34.262</td><td>4323</td></tr><tr><td rowspan="4">Memory</td><td>Decreasing</td><td>✓</td><td>✕</td><td>Minutes</td><td>1.34E+08</td><td>1.29E+08</td><td>1.29E+07</td><td>4324</td></tr><tr><td>increasing</td><td>✓</td><td>✕</td><td>Minutes</td><td>8.75E+07</td><td>8.64E+07</td><td>2.35E+07</td><td>4325</td></tr><tr><td>Periodic</td><td>✕</td><td>✓</td><td>Minutes</td><td>1.04E+08</td><td>1.04E+08</td><td>7.88E+06</td><td>4326</td></tr><tr><td>Random</td><td>✕</td><td>✓</td><td>Minutes</td><td>9.72E+07</td><td>9.74E+07</td><td>1.92E+06</td><td>4327</td></tr><tr><td rowspan="4">Response<br>Time</td><td>Decreasing</td><td>✓</td><td>✕</td><td>Minutes</td><td>514.907</td><td>561.575</td><td>162.394</td><td>4328</td></tr><tr><td>increasing</td><td>✓</td><td>✓</td><td>Minutes</td><td>557.310</td><td>624.800</td><td>194.021</td><td>4329</td></tr><tr><td>Periodic</td><td>✕</td><td>✓</td><td>Minutes</td><td>561.310</td><td>691.467</td><td>296.526</td><td>4330</td></tr><tr><td>Random</td><td>✕</td><td>✕</td><td>Minutes</td><td>476.822</td><td>454.164</td><td>150.803</td><td>4331</td></tr><tr><td rowspan="4">Traffic</td><td>Decreasing</td><td>✓</td><td>✕</td><td>Minutes</td><td>3046.082</td><td>3450.782</td><td>1147.120</td><td>4332</td></tr><tr><td>increasing</td><td>✓</td><td>✓</td><td>Minutes</td><td>3226.507</td><td>3679.959</td><td>1338.634</td><td>4333</td></tr><tr><td>Periodic</td><td>✕</td><td>✓</td><td>Minutes</td><td>3169.468</td><td>3803.333</td><td>1865.883</td><td>4334</td></tr><tr><td>Random</td><td>✕</td><td>✕</td><td>Minutes</td><td>2378.145</td><td>2132.667</td><td>968.229</td><td>4335</td></tr></tbody></table>

The following table describes the real-world series.

<table><thead><tr><th>Metric</th><th>Series</th><th>Trend</th><th>Stationary</th><th>Frequency</th><th>Mean</th><th>Median</th><th>Std</th><th>Size</th><th>Communication</th></tr></thead><tbody><tr><td rowspan="4">CPU<br>Usage</td><td>1</td><td>✕</td><td>✕</td><td>Seconds</td><td>0.34</td><td>0.33</td><td>0.05</td><td>1,426</td><td>RI, IC, IPC</td></tr><tr><td>2</td><td>✕</td><td>✓</td><td>Seconds</td><td>0.34</td><td>0.40</td><td>0.11</td><td>1,427</td><td>RI</td></tr><tr><td>3</td><td>✕</td><td>✕</td><td>Seconds</td><td>0.18</td><td>0.15</td><td>0.07</td><td>1,420</td><td>RI, IC, IPC</td></tr><tr><td>4</td><td>✕</td><td>✕</td><td>Seconds</td><td>0.32</td><td>0.31</td><td>0.04</td><td>1,421</td><td>RI, IC</td></tr><tr><td rowspan="4">Memory</td><td>1</td><td>✓</td><td>✕</td><td>Seconds</td><td>0.53</td><td>0.52</td><td>0.04</td><td>1,427</td><td>RI, IC</td></tr><tr><td>2</td><td>✕</td><td>✓</td><td>Seconds</td><td>0.51</td><td>0.50</td><td>0.03</td><td>1,426</td><td>RI</td></tr><tr><td>3</td><td>✓</td><td>✓</td><td>Seconds</td><td>0.52</td><td>0.52</td><td>0.00</td><td>1,426</td><td>RI, IPC</td></tr><tr><td>4</td><td>✕</td><td>✓</td><td>Seconds</td><td>0.45</td><td>0.45</td><td>0.02</td><td>1,424</td><td>RI, IC</td></tr><tr><td rowspan="4">Response<br>Time</td><td>1</td><td>✕</td><td>✕</td><td>Minutes</td><td>1.00</td><td>1.02</td><td>0.20</td><td>720</td><td>RI</td></tr><tr><td>2</td><td>✕</td><td>✕</td><td>Minutes</td><td>23.75</td><td>23.95</td><td>3.06</td><td>720</td><td>RI</td></tr><tr><td>3</td><td>✓</td><td>✕</td><td>Minutes</td><td>59.94</td><td>58.24</td><td>14.79</td><td>721</td><td>IC</td></tr><tr><td>4</td><td>✕</td><td>✕</td><td>Minutes</td><td>470.38</td><td>371.96</td><td>255.56</td><td>715</td><td>IC</td></tr><tr><td rowspan="4">Traffic</td><td>1</td><td>✓</td><td>✕</td><td>Minutes</td><td>222.39</td><td>220.58</td><td>12.42</td><td>721</td><td>RI</td></tr><tr><td>2</td><td>✕</td><td>✕</td><td>Minutes</td><td>50.75</td><td>54.37</td><td>11.69</td><td>721</td><td>RI</td></tr><tr><td>3</td><td>✕</td><td>✕</td><td>Minutes</td><td>111.60</td><td>44.29</td><td>87.34</td><td>713</td><td>IC</td></tr><tr><td>4</td><td>✕</td><td>✕</td><td>Minutes</td><td>258.10</td><td>255.12</td><td>40.43</td><td>721</td><td>IPC</td></tr></tbody></table>
